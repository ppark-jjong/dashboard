1. 패키지 설치 및 환경 설정 명령어

pip install -r requirements.txt           # 의존성 패키지 설치
python -m pip install --upgrade pip       # pip 업그레이드
python -m venv venv                       # 가상 환경 생성
venv\Scripts\activate                     # 가상 환경 활성화
deactivate                                # 가상 환경 비활성화

netstat -a -o                             # 네트워크 포트 확인
taskkill /f /pid PID번호                  # 특정 PID 프로세스 종료

protoc -I=protos --python_out=protos protos/delivery_status.proto        # ProtoBuf 컴파일
protoc --proto_path=. -I . --python_out=. --pyi_out=. ./realtime_status.proto  # 실시간 상태 proto 파일 컴파일



======================================================================================
2. Docker 및 Docker Compose 명령어

docker-compose down                                   # 기존 컨테이너 중지 및 제거
docker-compose build                                  # Docker 이미지 빌드
docker-compose -f docker/DockerFile build --no-cache  # Docker 이미지 빌드 (캐시 미사용)
docker-compose up                                     # Docker 컨테이너 실행
docker-compose up -d                                  # Docker 컨테이너 실행 (백그라운드 모드)
docker-compose -f docker/docker-compose.yaml up -d    # 특정 compose 파일 실행

docker-compose ps                                     # 실행 상태 확인
docker images                                         # 도커 이미지 목록 확인
docker-compose logs -f                                # 실시간 로그 확인

docker exec -it <container_name> /bin/bash            # 컨테이너 내부 접근
docker cp test-kafka.py <container_name>:/path/to/new_directory/  # 컨테이너에 파일 복사




======================================================================================
3. Kafka CLI 명령어

docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092  # Kafka 토픽 목록 조회
/usr/bin/kafka-topics --bootstrap-server localhost:9092 --delete --topic delivery-data  # 특정 토픽 삭제




======================================================================================
4. Google Cloud Platform (GCP) 명령어

gcloud auth activate-service-account --key-file=C:\MyMain\dashboard\secrets\google\credentials.json  # 서비스 계정 인증
gcloud init                                   # 초기화
gcloud auth login                             # 인증 로그인
gcloud auth list                              # 인증 목록 조회
gcloud config set project [PROJECT_ID]        # 프로젝트 ID 설정
gcloud config set account                     # 계정 설정
gcloud projects list                          # 프로젝트 목록 조회
gcloud auth revoke --all                      # 모든 인증 해제

$PROJECT_ID = "dashboard-440518"
$IMAGE_NAME = "fastapi-webhook"

docker run -e PORT=8080 -p 8080:8080 asia-northeast3-docker.pkg.dev/${PROJECT_ID}/teckwah-data/${IMAGE_NAME}:latest  # Docker 실행
docker build --no-cache -t asia-northeast3-docker.pkg.dev/${PROJECT_ID}/teckwahkr-artifactregistry/${IMAGE_NAME}:latest -f docker/Dockerfile-fastapi .  # Docker 이미지 빌드
docker push asia-northeast3-docker.pkg.dev/${PROJECT_ID}/teckwahkr-artifactregistry/${IMAGE_NAME}:latest  # Artifact Registry에 이미지 푸시
gcloud auth configure-docker asia-northeast3-docker.pkg.dev  # Artifact Registry Docker 인증
gcloud run deploy SERVICE_NAME --image=asia-northeast3-docker.pkg.dev/${PROJECT_ID}/teckwah-data/${IMAGE_NAME}:latest --region=asia-northeast3  # 수동 배포




======================================================================================
5. Cloud Function 로컬 테스트 명령어

# Functions Framework 구동
python -m functions_framework --target=kafka_stream --source=src/api/cloud_function_api.py  

# 로컬 Cloud Function 데이터 테스트
Invoke-WebRequest -Uri "http://127.0.0.1:8080" -Method POST -ContentType "application/json" -InFile "data/data.json"  

Invoke-WebRequest -Uri "http://127.0.0.1:8080/webhook" -Method POST -ContentType "application/json" -InFile "data/data.json"



# 로컬에서 Uvicorn 구동
uvicorn src.api.main_api:app --host 0.0.0.0 --port 8080





=============================================================================
6. 분석 목표 및 트렌드 모니터링 주제

실시간 배송 상태 및 KPI 모니터링 
	-테이블 대시보드

배송 트렌드 분석 :  SLA 타입별, 요일별 배송 개수, 위치별 배송 갯수, 기사별 배송 갯수 및 거리
	- 히트맵

배송 트렌드 분석 : SLA 타입별 배송 개수, 요일별 배송 개수, 위치별 배송 갯수, 기사별 배송 갯수 및 거리
	- 히트맵, 막대, 선 그래프, 


1. dashboard 용 토픽 ('Delivery', 'DPS', 'ETA', 'SLA', 'Address', 'Status', 'Billed Distance', 'Recipient') 이 토픽은 고정이야
2. 각 지역별 배송 히트맵 및 트렌드
   지역별 자주 배송 가는 지역
   지역별 분류별 트렌드
   지역별 기사 배차 트렌드
   
3. data(주문접수) 요일별 시간별 배송 접수 트렌드 
   어떤 요일에 많은 량이 접수되는가, 어떤 분류가 어떤 요일에 많이 접수되는가
   미스가 난다면 어떤요일에 어떤 분류가 많이 접수 미스가 나는가
   어떤 요일 어떤 시간에 많이 접수되는가 (1시간 단위)
4. 특정 시간대에 특정 지역으로의 배송량 확인
    traffic jam인 시간대에 eta로 접수되어 긴급한 배송 건수

=============================================================================
7. 프로젝트 구조 (파일 및 폴더)

main/
├── src/
│   ├── api/                           	# API 관련 코드
│       ├── main_api.py               	# API 관련 통합 엔드포인트 모음 코드
│   ├── kafka/                         	# 메시지 브로커 관련 코드
│       ├── producer.py                # Kafka Producer - 데이터 전송
│       ├── consumer.py               # Kafka Consumer - PySpark와 연동
│   ├── collectors/                    	# 데이터 수집 관련 코드
│       ├── google_sheet.py           # Google Sheets 데이터 수집 관련 코드
│       ├── crawler.py                 	# 웹 크롤러를 통한 데이터 수집
│   ├── config/                        	# 설정 관련 코드
│       ├── config_data_format.py   # Kafka, Spark 데이터 전처리 시 format 관련 설정
│       ├── config_google.py        	# GCS, Google Sheets 설정
│       ├── config_crawler.py         # Web Crawler 설정
│       ├── config_manager.py       # 전체 설정 관리 파일
│   ├── processors/                    # 데이터 처리 관련 코드
│       ├── processor_manager.py 	# 데이터 처리 클래스 소프트 코딩 관리
│       ├── processor_common.py 	# 데이터 처리 공통 메서드 관리
│       ├── processor_regional.py 	# 지역별 배송 트렌드 로직
│       ├── processor_time.py 		# 시간대, 요일별 트렌드 로직
│       ├── processor_distance.py 	# 거리별 예측 데이터 로직
│       ├── processor_driver.py 		# 기사별 배송 트렌드 로직
├── docker/
│   ├── Dockerfile                    	# 도커 이미지 빌드 설정
│   ├── docker-compose.yaml     	# 도커 컴포즈 설정 (Kafka, PySpark, Zookeeper)
├── secrets/                           	# 민감한 정보 (API 인증 정보 등)
│   └── google/                    	# Google API 인증서 파일
│       └── credentials.json           # Google API 인증서
├── data/
│   ├──  data.json                     # 임시 데이터
└── requirements.txt                   # 프로젝트 의존성 관리





======================================================================================
8. 추가 JAR 파일 목록

commons-pool2-2.11.1.jar
kafka-clients-3.4.0.jar
spark-protobuf_2.12-3.4.1.jar
spark-sql-kafka-0-10_2.12-3.4.1.jar
spark-token-provider-kafka-0-10_2.12-3.4.1.jar
